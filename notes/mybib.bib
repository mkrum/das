
@article{alphazero,
        author = {David Silver  and Thomas Hubert  and Julian Schrittwieser  and Ioannis Antonoglou  and Matthew Lai  and Arthur Guez  and Marc Lanctot  and Laurent Sifre  and Dharshan Kumaran  and Thore Graepel  and Timothy Lillicrap  and Karen Simonyan  and Demis Hassabis },
        title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
        journal = {Science},
        volume = {362},
        number = {6419},
        pages = {1140-1144},
        year = {2018},
        doi = {10.1126/science.aar6404},
        URL = {https://www.science.org/doi/abs/10.1126/science.aar6404},
        eprint = {https://www.science.org/doi/pdf/10.1126/science.aar6404},
abstract = {Computers can beat humans at increasingly complex games, including chess and Go. However, these programs are typically constructed for a particular game, exploiting its properties, such as the symmetries of the board on which it is played. Silver et al. developed a program called AlphaZero, which taught itself to play Go, chess, and shogi (a Japanese version of chess) (see the Editorial, and the Perspective by Campbell). AlphaZero managed to beat state-of-the-art programs specializing in these three games. The ability of AlphaZero to adapt to various game rules is a notable step toward achieving a general game-playing system. Science, this issue p. 1140; see also pp. 1087 and 1118 AlphaZero teaches itself to play three different board games and beats state-of-the-art programs in each. The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.}}

@article{giraffe,
author    = {Matthew Lai},
title     = {Giraffe: Using Deep Reinforcement Learning to Play Chess},
journal   = {CoRR},
volume    = {abs/1509.01549},
year      = {2015},
url       = {http://arxiv.org/abs/1509.01549},
eprinttype = {arXiv},
eprint    = {1509.01549},
timestamp = {Mon, 13 Aug 2018 16:47:30 +0200},
biburl    = {https://dblp.org/rec/journals/corr/Lai15a.bib},
bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{alphago,
abstract = {The game of Go has long been viewed as the most challenging of classic games for artificial intelligence owing to its enormous search space and the difficulty of evaluating board positions and moves. Here we introduce a new approach to computer Go that uses 'value networks' to evaluate board positions and 'policy networks' to select moves. These deep neural networks are trained by a novel combination of supervised learning from human expert games, and reinforcement learning from games of self-play. Without any lookahead search, the neural networks play Go at the level of state-of-the-art Monte Carlo tree search programs that simulate thousands of random games of self-play. We also introduce a new search algorithm that combines Monte Carlo simulation with value and policy networks. Using this search algorithm, our program AlphaGo achieved a 99.8 percent winning rate against other Go programs, and defeated the human European Go champion by 5 games to 0. This is the first time that a computer program has defeated a human professional player in the full-sized game of Go, a feat previously thought to be at least a decade away.},
added-at = {2016-05-21T09:09:48.000+0200},
author = {Silver, David and Huang, Aja and Maddison, Chris J. and Guez, Arthur and Sifre, Laurent and van den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and Dieleman, Sander and Grewe, Dominik and Nham, John and Kalchbrenner, Nal and Sutskever, Ilya and Lillicrap, Timothy and Leach, Madeleine and Kavukcuoglu, Koray and Graepel, Thore and Hassabis, Demis},
biburl = {https://www.bibsonomy.org/bibtex/29e987f58d895c490144693139cbc90c7/flint63},
doi = {10.1038/nature16961},
file = {Nature online:2016/SilverHuangEtAl16nature.pdf:PDF},
groups = {public},
interhash = {48430c7891aaf9fe2582faa8f5d076c1},
intrahash = {9e987f58d895c490144693139cbc90c7},
issn = {0028-0836},
journal = {Nature},
keywords = {01614 paper ai google learn algorithm},
month = {jan},
number = 7587,
pages = {484--489},
timestamp = {2018-04-16T12:03:12.000+0200},
title = {Mastering the Game of {Go} with Deep Neural Networks and Tree Search},
username = {flint63},
volume = 529,
year = 2016
}

@article{transformer,
author    = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia},
title     = {Attention Is All You Need},
title: = {Attention Is All You Need},
journal   = {ArXiv},
year      = {2017},
url       = {http://arxiv.org/abs/1706.03762},
}


@inproceedings{pretraining,
title={Improving Language Understanding by Generative Pre-Training},
author={Alec Radford and Karthik Narasimhan},
year={2018}
}

@article{thinkingliketransformers,
author    = {Gail Weiss and Yoav Goldberg and Eran Yahav},
title     = {Thinking Like Transformers},
journal   = {CoRR},
volume    = {abs/2106.06981},
year      = {2021},
url       = {https://arxiv.org/abs/2106.06981},
eprinttype = {arXiv},
eprint    = {2106.06981},
timestamp = {Tue, 15 Jun 2021 16:35:15 +0200},
biburl    =
{https://dblp.org/rec/journals/corr/abs-2106-06981.bib},
bibsource = {dblp computer science bibliography,
https://dblp.org}
}

@article{snnaa,
author    = {William Merrill},
title     = {Sequential Neural Networks as Automata},
journal   = {CoRR},
volume    = {abs/1906.01615},
year      = {2019},
url       = {http://arxiv.org/abs/1906.01615},
eprinttype = {arXiv},
eprint    = {1906.01615},
timestamp = {Thu, 13 Jun 2019 13:36:00 +0200},
biburl    = {https://dblp.org/rec/journals/corr/abs-1906-01615.bib},
bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{scalinglaws,
author    = {Jared Kaplan and
Sam McCandlish and
Tom Henighan and
Tom B. Brown and
Benjamin Chess and
Rewon Child and
Scott Gray and
Alec Radford and
Jeffrey Wu and
Dario Amodei},
title     = {Scaling Laws for Neural Language Models},
journal   = {CoRR},
volume    = {abs/2001.08361},
year      = {2020},
url       = {https://arxiv.org/abs/2001.08361},
eprinttype = {arXiv},
eprint    = {2001.08361},
timestamp = {Wed, 03 Jun 2020 10:55:13 +0200},
biburl    = {https://dblp.org/rec/journals/corr/abs-2001-08361.bib},
bibsource = {dblp computer science bibliography, https://dblp.org}
}

@TECHREPORT{passive,
author = {Kevin P. Murphy},
title = {Passively Learning Finite Automata},
institution = {},
year = {1995}
}

@MISC{Lang98,
author = {Kevin Lang},
title = {Random DFA's can be Approximately Learned from Sparse Uniform Examples},
year = {1998}
}

@article{otherTSP,
          author    = {Xavier Bresson and
                                      Thomas Laurent},
          title     = {The Transformer Network for the Traveling Salesman Problem},
            journal   = {CoRR},
              volume    = {abs/2103.03012},
                year      = {2021},
                  url       = {https://arxiv.org/abs/2103.03012},
                    eprinttype = {arXiv},
                      eprint    = {2103.03012},
                        timestamp = {Mon, 15 Mar 2021 17:30:55 +0100},
                          biburl    = {https://dblp.org/rec/journals/corr/abs-2103-03012.bib},
                            bibsource = {dblp computer science bibliography, https://dblp.org}
}
@misc{wouter,
          doi = {10.48550/ARXIV.1803.08475},
            
            url = {https://arxiv.org/abs/1803.08475},
              
              author = {Kool, Wouter and van Hoof, Herke and Welling, Max},
                
                keywords = {Machine Learning (stat.ML), Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
                  
                  title = {Attention, Learn to Solve Routing Problems!},
                    
                    publisher = {arXiv},
                      
                      year = {2018},
                        
                        copyright = {arXiv.org perpetual, non-exclusive license}
}

